{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Model with Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Now that you have learned the basics of the Flask web framework, you will combine that knowledge with your prior knowledge of cloud functions to deploy a machine learning model as an HTTP API with Flask!\n",
    "\n",
    "Clone this repository and work locally so that you can run and test your Flask app. Start by running `jupyter notebook` so that you can run the code examples in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this lesson you will:\n",
    "\n",
    "* Recall the model pickling and unpickling process from the cloud function approach\n",
    "* Incorporate a model prediction function into a Flask web app\n",
    "* Deploy a machine learning model as an HTTP API using Flask and Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall: Cloud Functions\n",
    "\n",
    "In a previous lesson, you were introduced to cloud functions. With a cloud function, you need:\n",
    "\n",
    "1. A pickled model file\n",
    "2. A Python file defining the function\n",
    "3. A requirements file\n",
    "\n",
    "We will reuse the model file and Python code from the previous cloud functions lesson, so you may want to go back and review that lesson if you're confused about any of the details.\n",
    "\n",
    "The model file has already been included in this repository as `model.pkl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also be reusing this code from the cloud function:\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "def iris_prediction(sepal_length, sepal_width, petal_length, petal_width):\n",
    "    \"\"\"\n",
    "    Given sepal length, sepal width, petal length, and petal width,\n",
    "    predict the class of iris\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the model from the file\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        model = joblib.load(f)\n",
    "        \n",
    "    # Construct the 2D matrix of values that .predict is expecting\n",
    "    X = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    \n",
    "    # Get a list of predictions and select only 1st\n",
    "    predictions = model.predict(X)\n",
    "    prediction = int(predictions[0])\n",
    "    \n",
    "    return {\"predicted_class\": prediction}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll also build our environment starting with the `requirements.txt` from that lesson:\n",
    "\n",
    "```\n",
    "scikit-learn==0.23.2\n",
    "joblib==0.17.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Functions without Flask\n",
    "\n",
    "Previously, we deployed this cloud function using this `predict` function:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "def predict(request):\n",
    "    \"\"\"\n",
    "    `request` is an HTTP request object that will automatically be passed\n",
    "    in by Google Cloud Functions\n",
    "    \n",
    "    You can find all of its properties and methods here:\n",
    "    https://flask.palletsprojects.com/en/1.0.x/api/#flask.Request\n",
    "    \"\"\"\n",
    "    # Get the request data from the user in JSON format\n",
    "    request_json = request.get_json()\n",
    "    \n",
    "    # We are expecting the request to look like this:\n",
    "    # {\"sepal_length\": <x1>, \"sepal_width\": <x2>, \"petal_length\": <x3>, \"petal_width\": <x4>}\n",
    "    # Send it to our prediction function using ** to unpack the arguments\n",
    "    result = iris_prediction(**request_json)\n",
    "    \n",
    "    # Return the result as a string with JSON format\n",
    "    return json.dumps(result)\n",
    "```\n",
    "\n",
    "Then bundling the model file, Python file, and requirements file into a single archive and uploading that to Google Cloud Functions.\n",
    "\n",
    "That required a fair amount of configuration within Google Cloud Functions to specify the function to be invoked (`predict`), the permissions (public on the web), and the storage location for the archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Functions with Flask\n",
    "\n",
    "When using Flask directly (rather than via the Google Cloud Functions implementation) and deploying on Heroku, we will need to import and declare a few more things within the code itself, but at the same time we won't need to configure as much within the website interface. We'll also be able to test our code locally!\n",
    "\n",
    "### Recall: Flask App Basics\n",
    "\n",
    "Here was the source code of our previous simple Flask app:\n",
    "\n",
    "```python\n",
    "# import flask here\n",
    "from flask import Flask\n",
    "\n",
    "# create new flask app here\n",
    "app = Flask(__name__)\n",
    "\n",
    "# define routes for your new flask app\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return 'Hello, world!'\n",
    "```\n",
    "\n",
    "We imported the Flask library, created a Flask app, and defined a single route `/`, which just returns the text `'Hello, world!'`.\n",
    "\n",
    "Now let's add in those functions from our cloud function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ML Prediction Functionality to Our Flask App\n",
    "\n",
    "#### Imports\n",
    "\n",
    "Instead of just importing Flask, we'll also need to add in the `joblib` and `json` imports from the cloud function. We also need to import `request` from Flask so that we can parse the request data.\n",
    "\n",
    "```python\n",
    "# Flask is the overall web framework\n",
    "from flask import Flask, request\n",
    "# joblib is used to unpickle the model\n",
    "import joblib\n",
    "# json is used to prepare the result\n",
    "import json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flask App Setup\n",
    "\n",
    "This is the same as in our simple Flask app:\n",
    "\n",
    "```python\n",
    "# create new flask app here\n",
    "app = Flask(__name__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Cloud Function\n",
    "\n",
    "Then we include our `iris_prediction` function from previously. In a more complex Flask app, this would likely be stored in a separate `.py` file, but we're keeping it all in one place for the sake of simplicity.\n",
    "\n",
    "```python\n",
    "def iris_prediction(sepal_length, sepal_width, petal_length, petal_width):\n",
    "    \"\"\"\n",
    "    Given sepal length, sepal width, petal length, and petal width,\n",
    "    predict the class of iris\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the model from the file\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        model = joblib.load(f)\n",
    "\n",
    "    # Construct the 2D matrix of values that .predict is expecting\n",
    "    X = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "\n",
    "    # Get a list of predictions and select only 1st\n",
    "    predictions = model.predict(X)\n",
    "    prediction = int(predictions[0])\n",
    "\n",
    "    return {\"predicted_class\": prediction}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Routes\n",
    "\n",
    "For now, let's keep the `/` route as-is, then also add the `/predict` route.\n",
    "\n",
    "Some notes on this change:\n",
    "\n",
    "* `/predict` accepts HTTP `POST` requests, which is conventional for a form submission. Therefore we specify `methods=['POST']`\n",
    "* Instead of having `request` be a function parameter like it was in our cloud function, instead it's something we imported earlier. However it works the same way as the function parameter.\n",
    "\n",
    "```python\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return 'Hello, world!'\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the request data from the user in JSON format\n",
    "    request_json = request.get_json()\n",
    "\n",
    "    # We are expecting the request to look like this:\n",
    "    # {\"sepal_length\": <x1>, \"sepal_width\": <x2>, \"petal_length\": <x3>, \"petal_width\": <x4>}\n",
    "    # Send it to our prediction function using ** to unpack the arguments\n",
    "    result = iris_prediction(**request_json)\n",
    "\n",
    "    # Return the result as a string with JSON format\n",
    "    return json.dumps(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling It All Together\n",
    "\n",
    "When we bring together the imports, app setup, cloud function, and routes, the entire contents of `app.py` looks like this:\n",
    "\n",
    "```python\n",
    "# Flask is the overall web framework\n",
    "from flask import Flask, request\n",
    "# joblib is used to unpickle the model\n",
    "import joblib\n",
    "# json is used to prepare the result\n",
    "import json\n",
    "\n",
    "# create new flask app here\n",
    "app = Flask(__name__)\n",
    "\n",
    "# helper function here\n",
    "\n",
    "def iris_prediction(sepal_length, sepal_width, petal_length, petal_width):\n",
    "    \"\"\"\n",
    "    Given sepal length, sepal width, petal length, and petal width,\n",
    "    predict the class of iris\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the model from the file\n",
    "    with open(\"model.pkl\", \"rb\") as f:\n",
    "        model = joblib.load(f)\n",
    "\n",
    "    # Construct the 2D matrix of values that .predict is expecting\n",
    "    X = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "\n",
    "    # Get a list of predictions and select only 1st\n",
    "    predictions = model.predict(X)\n",
    "    prediction = int(predictions[0])\n",
    "\n",
    "    return {\"predicted_class\": prediction}\n",
    "\n",
    "# defining routes here\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return 'Hello, world!'\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the request data from the user in JSON format\n",
    "    request_json = request.get_json()\n",
    "\n",
    "    # We are expecting the request to look like this:\n",
    "    # {\"sepal_length\": <x1>, \"sepal_width\": <x2>, \"petal_length\": <x3>, \"petal_width\": <x4>}\n",
    "    # Send it to our prediction function using ** to unpack the arguments\n",
    "    result = iris_prediction(**request_json)\n",
    "\n",
    "    # Return the result as a string with JSON format\n",
    "    return json.dumps(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Flask App Locally\n",
    "\n",
    "You should already have a local environment called `flask-env` from the **Introduction to Flask** lesson. If you do not, go back to that lesson and follow the steps under `Setting up a Flask Environment`.\n",
    "\n",
    "### Preparing the Environment\n",
    "\n",
    "Run this code in a new terminal window (separate from where you are running `jupyter notebook`) to activate `flask-env`:\n",
    "\n",
    "```bash\n",
    "conda activate flask-env\n",
    "```\n",
    "\n",
    "This environment has everything you need to run a basic Flask app, but it doesn't have the cloud function dependencies yet.\n",
    "\n",
    "Run these commands in the terminal to install those dependencies:\n",
    "\n",
    "```bash\n",
    "pip install joblib==0.17.0\n",
    "pip install scikit-learn==0.23.2\n",
    "```\n",
    "\n",
    "Now we should be ready to run our app!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Flask Application\n",
    "\n",
    "As previously, run this command in the terminal from the root of this repository:\n",
    "\n",
    "Mac or UNIX:\n",
    "\n",
    "```bash\n",
    "export FLASK_ENV=development\n",
    "env FLASK_APP=app.py\n",
    "flask run\n",
    "```\n",
    "\n",
    "Windows:\n",
    "\n",
    "```bash\n",
    "set FLASK_APP=newproj\n",
    "set FLASK_ENV=development\n",
    "flask run\n",
    "```\n",
    "\n",
    "If you open [http://127.0.0.1:5000/](http://127.0.0.1:5000/) in the browser, you should see this, just like before:\n",
    "\n",
    "![hello world page](https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png)\n",
    "\n",
    "**Leave the server running** and let's use the `requests` library to send a request to our app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    url=\"http://127.0.0.1:5000/predict\",\n",
    "    json={\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected output of the above code cell is `<Response [200]>`. If you get a different response code, make sure that the code above matches the Flask app output where it says \"Running on\". For example, if you're running on port 5001 instead of 5000, make sure the `url` specified above matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_class': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You have now made an API request to a locally-running Flask app!\n",
    "\n",
    "**Go ahead and shut down the current Flask app by typing control-C in the terminal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying to Heroku\n",
    "\n",
    "The real goal of deploying an app is not just to get a web server running on your local computer, it's to get it hosted live on the web!\n",
    "\n",
    "[Heroku](https://www.heroku.com/) is a platform-as-a-service company that is great for hosting this kind of application. We'll plan to use that, because it has a completely-free tier and allows you to host a Flask app with minimal setup steps.\n",
    "\n",
    "### Preparing the Repository for Heroku\n",
    "\n",
    "#### Running a Production Server\n",
    "\n",
    "Previously when we ran our Flask app, it was always in development mode. This is useful for playing around and editing code, but is unnecessarily slow for a published app.\n",
    "\n",
    "Let's use a production-quality web server called [Waitress](https://docs.pylonsproject.org/projects/waitress/en/latest/).\n",
    "\n",
    "First, install it in the `flask-env`:\n",
    "\n",
    "```bash\n",
    "pip install waitress==2.1.1\n",
    "```\n",
    "\n",
    "Now instead of the `flask run` command, use this command to run the production server:\n",
    "\n",
    "```bash\n",
    "waitress-serve --port=5000 app:app\n",
    "```\n",
    "\n",
    "(You may need to allow Python to access the network, if your operating system gives you a pop-up.)\n",
    "\n",
    "This should produce an output like this:\n",
    "\n",
    "```\n",
    "INFO:waitress:Serving on http://0.0.0.0:5000\n",
    "```\n",
    "\n",
    "Just like before, you should be able to copy the specified URL, paste it into the browser, and see your \"Hello, World!\" page.\n",
    "\n",
    "The code below should also work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_class': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    url=\"http://0.0.0.0:5000/predict\",\n",
    "    json={\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2}\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! **Go ahead and shut down the server again using control-C.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements Files\n",
    "\n",
    "When we made a cloud function for Google Cloud Functions, we used a `requirements.txt` file. For Heroku, we'll need three files like this:\n",
    "\n",
    "1. `runtime.txt`: tells Heroku that we are running a Python application, and what version of Python\n",
    "2. `requirements.txt`: lists the required Python packages (same as we did for the Google Cloud Function, adding Flask as a requirement)\n",
    "3. `Procfile`: tells Heroku what command to run\n",
    "\n",
    "All of these files are already located in this repository, but we'll explain how they work below so that you know how to make your own!\n",
    "\n",
    "Our `runtime.txt` looks like this:\n",
    "\n",
    "```\n",
    "python-3.8.13\n",
    "```\n",
    "\n",
    "This is because we are running Python 3.8 in this conda environment. If you get an error about the \"runtime\" when trying to deploy with Heroku, it's possible that this version of Python is no longer supported. Look at the [supported runtimes](https://devcenter.heroku.com/articles/python-support#supported-runtimes) list to find other options.\n",
    "\n",
    "Our `requirements.txt` looks like this:\n",
    "\n",
    "```\n",
    "Flask==2.0.3\n",
    "joblib==0.17.0\n",
    "scikit-learn==0.23.2\n",
    "waitress==2.1.1\n",
    "```\n",
    "\n",
    "Those are all the packages we installed with pip!\n",
    "\n",
    "Finally, our `Procfile` looks like this:\n",
    "\n",
    "```\n",
    "web: waitress-serve --port=$PORT app:app\n",
    "```\n",
    "\n",
    "This is similar to what we ran in the terminal locally, except we added a `web:` to the beginning to indicate that this is a web process, and we parameterized `$PORT` so that it will use whatever port Heroku is configured to use, rather than hard-coding it to 5000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the App on Heroku\n",
    "\n",
    "Go to [https://signup.heroku.com/login](https://signup.heroku.com/login) and create an account (or log in if you already have one).\n",
    "\n",
    "Then go to [https://dashboard.heroku.com/new-app](https://dashboard.heroku.com/new-app) to make a new app on Heroku.\n",
    "\n",
    "> The name can be anything you want, but must be unique. You can fill in a name if you have one in mind, or you can just click **Create app** and you'll get a randomly-suggested name.\n",
    "\n",
    "Scroll down to **Deployment method** and choose **GitHub**. This will open another menu section, where you should click the **Connect to GitHub** button. You will get a pop-up window where you will be asked to sign in with GitHub.\n",
    "\n",
    "Once connected, a text box should appear where you can search for the repository you want to use. (If you're just practicing with this lesson repo, make sure you have forked this repo to your GitHub account, then search for the lesson repo name.) Click **Search**, then click **Connect** on the appropriate repository.\n",
    "\n",
    "Scroll down to **Manual deploy**, choose the appropriate branch, and click **Deploy Branch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything goes smoothly, you should see a build log, then the message **Your app was successfully deployed.** Then if you click the **View** button, that should open the \"Hello, World!\" page in a new browser tab.\n",
    "\n",
    "In the cell below, replace the value of `base_url` with your actual Heroku app URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base URL (ending with .herokuapp.com, no trailing /)\n",
    "base_url = \"\"\n",
    "response = requests.post(\n",
    "    url=f\"{base_url}/predict\",\n",
    "    json={\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2}\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Workflow on Heroku\n",
    "\n",
    "Especially because the [supported runtimes](https://devcenter.heroku.com/articles/python-support#supported-runtimes) list changes very frequently, it's likely that your deployment won't succeed on the first try. That's ok!\n",
    "\n",
    "#### Identifying the Problem\n",
    "\n",
    "**First make sure that the code works on your local computer.** It is MUCH easier to debug when working locally vs. working on a cloud service like Heroku!\n",
    "\n",
    "**Then make sure you read the error message** to understand what is going on and why:\n",
    "\n",
    "* Are any of the necessary files missing? Double-check that you used Git to add, commit, and push all of the relevant pieces:\n",
    "  * `runtime.txt`: the Python version\n",
    "  * `Procfile`: the terminal command for Heroku to run\n",
    "  * `requirements.txt`: the Python package requirements\n",
    "  * `app.py`: the actual Flask app source code\n",
    "  * `model.pkl`: the pickled model file\n",
    "* If the error message mentions the \"runtime\", you probably need to review the list of supported runtimes and modify `runtime.txt` so that it reflects the new version\n",
    "* If the error message happens during the `pip install` step, that might mean that one of the packages you're using is no longer available from the Python Package Index (the source where `pip` installs things from). Go to [https://pypi.org/](https://pypi.org/) to research the packages you are trying to use, make a new `conda` environment locally, and try installing the packages one by one until you have a working `requirements.txt` file.\n",
    "* If the error message happens when you're actually trying to view a page or run `requests.post`, most likely you didn't include all of the requirements in `requirements.txt`. You can run `pip freeze` in the terminal to see all of the packages you're using locally\n",
    "* If the build logs aren't giving you enough information, go to **More** --> **View logs** to see the logs from the actual application running. This will give you information about the incoming requests.\n",
    "\n",
    "#### Updating the Source Code on Heroku\n",
    "\n",
    "First, use Git to add, commit, and push your changes to GitHub. Then go back to the **Deploy** tab, scroll to the bottom, and click **Deploy Branch**. Then wait to see if you get the \"Your app was successfully deployed\" message, and repeat the \"Identifying the Problem\" steps as needed.\n",
    "\n",
    "You can also enable automatic deploys if you want to, but we tend to find that the manual process is easier to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up\n",
    "\n",
    "Currently we are mainly using Flask to serve JSON content, but Flask is also a web server that can serve HTML!\n",
    "\n",
    "If you are comfortable writing HTML, try modifying the `/` route so that it displays useful information, e.g. explaining how to call the API and make a prediction.\n",
    "\n",
    "You can write multi-line HTML directly within `app.py` using a triple-quoted Python string like this:\n",
    "\n",
    "```python\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return \"\"\"\n",
    "    <h1>API Documentation</h1>\n",
    "    <p>\n",
    "      Paragraph of text here\n",
    "    </p>\n",
    "    \"\"\"    \n",
    "```\n",
    "\n",
    "Alternatively, you can create a `static` folder containing a file called `index.html`, then re-write the `/` route so it looks like this:\n",
    "\n",
    "```python\n",
    "from flask import send_from_directory\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return send_from_directory(\"static\", \"index.html\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "That's it! You have now learned about how to incorporate a cloud function into a Flask app, and how to deploy that Flask app on Heroku!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
